<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>ISWC2017 Tutorial</title>
  <link rel="stylesheet" href="style.css">
</head>
<body>
  <header>
    <h1>HDT (Queryable compression format for Linked Data)</h1>
    <p id="venue">
      <a href="http://iswc2017.semanticweb.org/">ISWC2017</a> Tutorial - Sunday 21st October 2017
    </p>
    <ul id="organizers">
        <li><a href="http://wouterbeek.com/">Wouter Beek</a>, VU University Amsterdam</li> 
        <li><a href="https://www.wu.ac.at/en/infobiz/team/fernandez/">Javier D. Fernández</a>, Vienna University of Economics and Business, Austria</li>
        <li><a href="https://ruben.verborgh.org/">Ruben Verborgh</a>, Ghent University – imec, Belgium</li>
      
    </ul>
  </header>
  <main>
    <section id="abstract">
      <h2>Abstract</h2>
      <!-- 200 word summary of the workshop purpose -->
      <!-- CONTEXT: Why the need is so pressing or important     -->
      <!-- NEED: Why something needed to be done at all          -->
      <!-- TASK: What was undertaken to address the need         -->
      <!-- OBJECT: What the present document does or covers      -->
      <!-- FINDINGS: What the work done yielded or revealed      -->
      <!-- CONCLUSION :What the findings mean for the audience   -->
      <!-- PERSPECTIVES: What the future holds, beyond this work -->
    <p>The steady adoption of Linked Data in recent years has led to a
    significant increase in the volume of RDF datasets.  The potential
    of this Semantic Big Data is under-exploited when data management
    is based on traditional, human-readable RDF representations, which
    add unnecessary overheads when storing, exchanging and consuming
    RDF in the context of a large-scale and machine-understandable
    Semantic Web.  HDT tackles this issue by proposing a binary
    representation for RDF data.  HDT can be seen as a compressed,
    self-contained triple store for RDF.  On the one hand, HDT
    represents RDF with compact data structures that enable the
    storage, parsing and loading of Big Semantic Data in compressed
    space.  At the same time, “the HDT data are the index”, and thus
    it can be used as a graph data store that reports competitive
    querying performance.  In this tutorial we will focus on providing
    a hands-on experience with HDT.  We will also welcome external
    presentations on related topics and a discussion on next steps for
    the interested community.</p>
      </section>
      
       <section id="motivation">
      <h2>Motivation</h2>
        
           <p>
        Although the amount of RDF data has grown impressively over the last decade,
             traditional RDF representations are dominated by a document-centric, human-readable view,
             hence they suffer from scalability problems due to the huge space they need,
             the powerful resources required to manage them, and the large time required for data retrieval on the Web. 
        </p>
           <p>
             This scenario calls for efficient and functional representation formats for RDF
             as an essential tool for RDF preservation, sharing, and management.
             HDT fills this gap and proposes a compact data structure and binary serialization format
             that keeps big datasets compressed,
             saving space while maintaining search and browse operations without prior decompression.
             This makes it an ideal format for storing and sharing RDF datasets on the Web.</p>
           <p>
        HDT has been adopted by the Semantic Web community because of
        its simplicity and its performance for data retrieval
        operations.  It is worth noting that it is successfully
        deployed in projects
        like <a href="http://linkeddatafragments.org/">Linked Data
        Fragments</a>, which provides a uniform and lightweight
        interface to access RDF in the Web, indexing/reasoning systems
        like HDT-FoQ or WaterFowl, recommender systems, mobile
        applications, and it is the main store behind
        the <a href="http://lodlaundromat.org/">LOD Laundromat</a>
        project serving a crawl of a very big subset of the Linked
        Open Data Cloud.  Thus, we expect this tutorial will be of
        particular relevance to ISWC, since it raises awareness of a
        practical technology for managing and serving Big Semantic Data.
           </p>
           
      <!-- Why is the topic timely and of particular interest to ISWC participants? What is the relation of this tutorial to other similar tutorials presented at other events? -->
           
         
           
           
    </section>

    <section id="description">
      <h2>Detailed Description</h2>
      <!-- Length (full day or half day), overview of content and schedule, description of learning outcomes, presentation style, tutorial format, justification of length if full day (why a half-day tutorial would not suffice), prior knowledge required by the attendees (No longer than two pages) -->
        <p>
        
        The HDT tutorial will be held in
        an innovative format in order to elicit unanswered questions
        about the HDT technology and the Big Semantic Data community.
        Thus, the program will be split into two parts, with a
        knowledge sharing session (tutorial) and participant
        presentations and open discussion (workshop).
        </p>
        <p>
          The knowledge sharing session will be composed of practical and hands-on lessons to acquire the following skills:
        </p>  
        <ul>
              <li> Foundations of HDT: representation, data management and data retrieval operations. 
              </li>
              <li> Development libraries, practical tools and use of HDT within Apache Jena. 
              </li>
              <li> Use of HDT through the Triple Pattern Fragments API.
              </li>
              <li> Use of HDT within LOD Laundromat and the LOD Lab.
              </li>
        </ul>
          
        <p>
          The interactive workshop will consists of short presentations
          and demos from invited speakers, as well as the response to our call for papers and call for action.
          The last session will be dedicated to establishing collaborations and defining concrete next steps
          towards better organizing our community and materialising actions to increase the impact on Linked Data management.  

      </p>
        <h3>Tentative Programme - Sunday 21st October 2017</h3>
        <table id="agenda" class="table-bordered">
        <thead>
        <tr>
            <th>Time</th>
            <th>Activity</th>
        </tr>
        </thead>
        <tbody>
        <tr>
            <td>9:00 - 9:40</td>
            <td>Welcome and HDT foundations</td>
        </tr>   
        <tr>
            <td>09:40 - 10:10</td>
            <td>Practical uses I: Linked Data Fragments
            </td>
        </tr>
           <tr>
            <td>10:10 - 10:30</td>
            <td>Practical uses II: LOD Laundromat
            </td>
        </tr>
        <tr>
            <td>10:30 - 11:00</td>
            <td>Coffee Break</td>
        </tr>
        <tr>
            <td>11:00 - 11:45</td>
            <td>Presentations - Different perspectives on the topic
              <ul><li>"Practical use of HDT within data.world". Bryon Jacob and Jonathan Ortiz, <a href="https://data.world/">data.world</a>
                </li>
              <li>"HDT as the backend engine for Query Answering over the Web of Data". Dennis Diefenbach, Laboratoire Hubert Curien, Saint Etienne, France. 
                </li>
                 <li>"Counting to K: Top k Shortest Path Queries with HDT". Vadim Savenkov, Vienna University of Economics and Business, Austria. 
                </li>
              </ul> 
          </td>
        </tr>
        <tr>
            <td>11:45 - 12:30</td>
            <td>Discussion: concrete next steps and closing remarks. Add your ideas and follow the minutes at: <a href="https://board.net/p/HDT-ISWC17">https://board.net/p/HDT-ISWC17</a></td>
        </tr>
        </tbody>
        </table>
    </section>

    <section id="material">
      <h2>Tutorial Material</h2>
      <!-- Overview of the material used for the tutorial. In case of slides, handouts or other teaching material please specify when the material will be made available and how (e.g, under a CC license to anyone, only to the attendees, not at all, and so on) (One to three paragraphs)-->
        <p>
        Material will be composed of slides, code snippets, datasets
          and existing libraries in <a href="https://github.com/rdfhdt">https://github.com/rdfhdt</a>.
          All tutorial material will be available to anyone on Github
          and the project website <a href="http://rdfhdt.org">http://rdfhdt.org</a>.
        </p>
      
    </section>
      
    <section id="audience">
      <h2>Audience</h2>
      <!-- Who and how many people are likely to attend?
           (One paragraph) -->
        
        We expect to attract Linked Data researchers and
        practitioners, in particular data publishers and consumers.
        The audience will benefit from attending this tutorial by
        learning about ways to scale up large semantic data management
        and data retrieval, as well as by being able to discuss their
        expectations, requirements and experiences with current RDF
        representations and triple stores at large scale.  We aim for
        an audience of at least 20 people.
        
    </section>

    <section id="EOI">
      <h2>Call for contributions</h2>
     <!-- Audio-visual or technical requirements and any special room requirements (One to two paragraphs). -->
        The main aim of the interactive workshop is to foster new ideas and perspectives on the HDT technology. We encourage any kind of contribution related to HDT and Big Semantic Data: use cases, research and demo papers making use of HDT, system descriptions, visionary papers, etc. Submissions will be managed through EasyChair (a link to the system will be provided soon). All relevant submissions will be shortly presented in the tutorial and the material will be published in this web for permanent archival. 
    </section>

    <section id="presenters">
      <h2>Presenters</h2>
      <!-- Name, affiliation, email address, homepage
           and short (one paragraph) biography of each chair,
           explaining the chair’s expertise for the workshop -->
       <div class="chair">
        <h3>Wouter Beek</h3>
        <p class="affiliation">VU University Amsterdam, The Netherlands</p>
        <p class="email"><a href="mailto:w.g.j.beek@vu.nl;?subject=HDT-ISWC2017Tutorial">w.g.j.beek@vu.nl</a></p>
        <p class="website"><a href="http://wouterbeek.com/">http://wouterbeek.com/</a></p>
        <img src="https://triply.cc/dist/5137e3103e2e9a30ff97e3550f13284d.jpg" alt="[Wouter Beek]" />
        <p class="bio">
        Wouter Beek received his Master’s in Logic from the Institute for Logic, Language and Computation (ILLC).
He is currently PhD researcher at VU University Amsterdam (VUA), working in the Knowledge Representation &amp; Reasoning (KR&amp;R) group. His research focuses on the development, deployment and analysis of large-scale heterogeneous knowledge bases and the way in which they enable unanticipated and innovative reuse. Wouter is the principle developer of the LOD Laundromat and LOD Lab. He has taught over ten courses in Artificial Intelligence and Philosophy.
             </p>
            </div>
      
      <div class="chair">
        <h3>Javier D. Fernández (primary contact)</h3>
        <p class="affiliation">Vienna University of Economics and Business, Austria</p>
        <p class="email"><a href="mailto:javier.fernandez@wu.ac.at;?subject=ISWC2017Tutorial">javier.fernandez@wu.ac.at</a></p>
        <p class="website"><a href="https://www.wu.ac.at/en/infobiz/team/fernandez/">https://www.wu.ac.at/en/infobiz/team/fernandez/</a></p>
        <img src="https://www.wu.ac.at/fileadmin/wu/d/i/infobiz/img/fernandez.jpg" alt="[Javier Fernández]" />
        <p class="bio">
         Javier D. Fernández holds a PhD in Computer Science by the University of Valladolid (Spain), and the University of Chile (Chile). His thesis addressed efficient management of Big Semantic Data, proposing HDT, a binary RDF representation for scalable publishing, exchanging and consumption in the Web of Data. Dr. Javier D. Fernandez is currently a post-doctoral research fellow under an FWF (Austrian Science funds) Lise-Meitner grant. His current research focuses on efficient management of Big Semantic Data, RDF streaming, archiving and querying dynamic Linked Data. He has published more than 40 articles in international conferences and workshops and was editor of the HDT W3C Member Submission.
        </p>
        </div>
      
       <div class="chair">
        <h3>Ruben Verborgh</h3>
        <p class="affiliation">Ghent University – imec, Belgium</p>
        <p class="email"><a href="mailto:ruben.verborgh@ugent.be?subject=HDT-ISWC2017Tutorial">ruben.verborgh@ugent.be</a></p>
        <p class="website"><a href="https://ruben.verborgh.org/">https://ruben.verborgh.org/</a></p>
        <img src="https://ruben.verborgh.org/images/ruben.jpg" alt="[Ruben Verborgh]" />
        <p class="bio">
          Ruben Verborgh is a researcher in semantic hypermedia
          at Ghent University – imec, Belgium
          and a postdoctoral fellow of the Research Foundation Flanders.
          He explores the connection between Semantic Web technologies
          and the Web’s architectural properties,
          with the ultimate goal of building more intelligent clients.
          Along the way, he became fascinated by Linked Data,
          REST/hypermedia, Web APIs, and related technologies.
          He’s a co-author of two books on Linked Data,
          and has contributed to more than 200 publications
          for international conferences and journals on Web-related topics.
        </p>
      </div>
        
    </section>

    <section id="pc">
      <h2>Program Committee</h2>
      <!-- Names and affiliations of potential PC members -->
      <p>
        The following people could be potential PC members for the call for papers and would help in the dissemination of the tutorial.
      </p>
      <ul>
        <li>Bryon Jacob, <a href="https://data.world/">data.world</a></li>
        <li>Miguel A. Martínez-Prieto, University of Valladolid</li>
        <li>Axel Polleres, Vienna University of Economics and Business</li>
        <li>Juan Sequeda, <a href="https://capsenta.com/">Capsenta</a></li>
        <li>Miel Vander Sande, Ghent University – imec</li>
        <li>Herbert Van de Sompel, Los Alamos National Laboratory</li>
        <li>Ruben Taelman, Ghent University – imec</li>
        <li>Claudio Gutiérrez, Universidad de Chile</li>
        <li>Oscar Corcho, Universidad Politécnica de Madrid</li>
        <li>Laurens Rietveld, Triply</li>
        <li>Nieves Brisaboa, University of A Coruña</li>
        <li>Antonio Fariña, University of A Coruña</li>
        <li>Mario Arias, Mario Arias Software</li>
        <li>Stefan Schlobach, VU University Amsterdam</li>
      </ul>
    </section>
  </main>
</body>
</html>
